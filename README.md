# Implement And Compare Victim Caches And Skewed Associative Caches

## Abstract
Speed is the major limiting factor for the performance of the computer, which majorly depend on data transferrate between processor and memory. Therefore, we use cache memory concept to improve latency between the main memory and processor. Several mapping techniques were used to map data into cache memory. Since L1 cache is direct mapped cache, it has one-to-one relation, different address of data will conflict for same location in L1 cache and hence there is a miss called conflict misses which leads to miss penalty thus decreasing the performance. In this project, we are going to implement two new cache schemes that are victim cache and skewed associative cache to basic RISC architecture and compare them based on miss rate. Although direct-mapped caches suffer from higher miss ratios as compared to set-associative caches, they are attractive for today's high-speed pipelined processors that require very low access times. Victim cache augments the direct-mapped main cache with a small fully associate cache, called victim cache that stores cache blocks evicted from the main cache because of replacements. We propose and evaluate an improvement of this scheme, called selective victim caching. In this scheme, incoming blocks into the first level cache are placed selectively in the main cache or a small victim cache by the use of a prediction scheme based on their history of use. In addition, interchanges of blocks between the main cache and the victim cache are also performed selectively. Another new cache scheme is skewed associative cache, where two mapping function is used to map the address into different banks with different location which is unlike in conventional cache scheme. The developed cache schemes was simulated and analysed using the sim-cache functional simulator of MIPS tool. The obtained results are analysed for performance. 